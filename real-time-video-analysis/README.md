I was working on various real time video analytics projects. I tried quite a bit of different architectures. First thing first: for “eye contact analysis” the keyword what you want to look for in the ML world is “gaze detection”.
 - Amazon Rekognition video: Surely the quickest time-to-market solution but it might have unaffordable costs for your use case (see bellow). In real-time scenario can be used for face detection (bounding box), face pose detection (yaw, pitch, roll) and facial landmarks detection (position of mouth, nose, eyes, etc) as well as face identification from a known database. You could check if you’re able to construct a reliable secondary model over the facial landmarks response to classify the emotions or maybe even the gaze direction. Note however that real time rekognition video analytics have quite high cost ($0.12/min, can be thousands of usd per month with continuous use) https://docs.aws.amazon.com/rekognition/latest/dg/streaming-video-kinesis-output-reference-detectedface.html
 - Running your custom model on SageMaker endpoint: this can be done with the Kinesis Video Inference Template Kit: https://aws.amazon.com/blogs/machine-learning/analyze-live-video-at-scale-in-real-time-using-amazon-kinesis-video-streams-and-amazon-sagemaker/ The blog posts describes how to do it, and this solution gives you flexibility to use your own  models. The problem might be again the cost, you’ll have to pay a good GPU endpoint per 2-3 video streams.
 - Edge inference: for real-time video analysis  in a sustainable way you’ll want to use edge inference i.e. you run your facial recognizer algorithm close to the camera that registers the video, on the hardware owned by you. You’ve a choice of different hw providers, for example a Raspberry pi + (Intel Movidius or Google Coral), or for something more serious, the nvidia Jetson platform that have system-on-a-chip solutions ranging from 60 to 2000 usd. All of them have a steep learning curve and you’ll to occupy also with IoT stuff (device provisioning, maintenance, etc) but you pay for the inference cost just once, up-front.
 - If I had to start today a real-time video analytics project, without hesitation I’d try Amazon Panorama, the device just announced at re:invent that does edge inference (with nvidia jetson inside) and promises to have a software stack that resolves most of the IoT related problems I mentioned above, just embedding the device directly to the AWS ecosystem.
